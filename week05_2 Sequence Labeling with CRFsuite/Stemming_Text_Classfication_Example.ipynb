{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 검사 생략\n"
     ]
    }
   ],
   "source": [
    "# Text classification Example\n",
    "\n",
    "# Data Load\n",
    "\n",
    "import csv\n",
    "\n",
    "file = open (\"./IMDB_Dataset.csv\", \"r\", encoding='UTF-8')  # ./ 기본경로는 Script가 저장되는 장소\n",
    "rdr = csv.reader(file)\n",
    "\n",
    "sentence = []\n",
    "label = []\n",
    "\n",
    "for index, line in enumerate(rdr):\n",
    "    if index == 0:\n",
    "        continue\n",
    "    sentence.append(line[0].strip()) # sentence 리스트에 리뷰 내용 추가, strip() 함수는 문자열 양쪽의 공백 제거 (x)\n",
    "    label.append(line[1].strip())    # label 리스트에 긍정, 부정 추가 (y)\n",
    "    \n",
    "# print data, not preprocessing (원본)\n",
    "print(\"원본 검사 생략\")\n",
    "#print(sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming 라이브러리 선언 및 테스트\n",
    "\n",
    "from __future__ import print_function\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "#print(stemmer.stem(\"hook\")) # stemmer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-86b4aa6ae6f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#temp_data[i].append(stemmer.stem(sentence[i]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\venv\\tensorflow\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mecho\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mecho\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# re 라이브러리로 특수문자 제거\n",
    "import re\n",
    "\n",
    "# 저장용 임시 리스트\n",
    "#temp_data = [len(sentence)]\n",
    "t_data=[]\n",
    "# 소문자로 변환 .lower(), 불필요한 특수문자 제거\n",
    "for i in range(len(sentence)):\n",
    "    sentence[i] = sentence[i].lower() # lower() : 모든 문자를 소문자로 변환\n",
    "    sentence[i] = re.sub(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\", ' ', sentence[i])\n",
    "    sentence[i] = re.sub(\"[.;:!\\'?,\\\"()|[\\]]\", ' ', sentence[i])\n",
    "    sentence[i] = sentence[i].split(' ') # 단어 단위 분할리스트 임시저장\n",
    "    # word split 정상 동작 확인\n",
    "    \n",
    "    #print(stemmer.stem(sentence[0][i])) #stemming 정상확인\n",
    "    #temp_data.append([])\n",
    "    for j in range(len(sentence[i])): # 분할한 데이터 stemming  \n",
    "        t_data.append(stemmer.stem(sentence[i][j]))\n",
    "        #temp_data[i].append(stemmer.stem(sentence[i]))\n",
    "        \n",
    "    print(t_data)\n",
    "    \n",
    "\n",
    "    \n",
    "#print(temp_data[0][0]) # 단어 분할까지 확인!\n",
    "\n",
    "    #for j in range(len(temp_data)):\n",
    "        \n",
    "        #t_data = list(len(temp_data))\n",
    "        #t_data.append(temp_data[j]) \n",
    "    #stemmer.stem(temp_data)\n",
    "    #sentence[i] = t_data\n",
    "    \n",
    "    # 리스트를 하나의 문장으로\n",
    "    #save_data[i] = \" \".join(stemmer.stem(temp_data[i]))\n",
    "    #data = \" \".join( stemmer.stem( temp_data ) )\n",
    "    \n",
    "# re 라이브러리로 불필요 문자 및 Stemming 전처리 완료  (단어 리스트 형태)\n",
    "\n",
    "#print(sente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', 'll', 'be', 'hooked', '', 'they', 'are', 'right', '', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', '', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', '', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', '', 'trust', 'me', '', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', '', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', '', 'sex', 'or', 'violence', '', 'its', 'is', 'hardcore', '', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', '', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', '', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', '', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', '', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', '', 'em', 'city', 'is', 'home', 'to', 'many', '', 'aryans', '', 'muslims', '', 'gangstas', '', 'latinos', '', 'christians', '', 'italians', '', 'irish', 'and', 'more', '', '', '', 'so', 'scuffles', '', 'death', 'stares', '', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', '', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'wouldn', 't', 'dare', '', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', '', 'forget', 'charm', '', 'forget', 'romance', '', '', 'oz', 'doesn', 't', 'mess', 'around', '', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', '', 'i', 'couldn', 't', 'say', 'i', 'was', 'ready', 'for', 'it', '', 'but', 'as', 'i', 'watched', 'more', '', 'i', 'developed', 'a', 'taste', 'for', 'oz', '', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', '', 'not', 'just', 'violence', '', 'but', 'injustice', '', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', '', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', '', 'well', 'mannered', '', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', '', 'watching', 'oz', '', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', '', '', '', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side', '', 'one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', 'll', 'be', 'hooked', '', 'they', 'are', 'right', '', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', '', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', '', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', '', 'trust', 'me', '', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', '', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', '', 'sex', 'or', 'violence', '', 'its', 'is', 'hardcore', '', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', '', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', '', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', '', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', '', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', '', 'em', 'city', 'is', 'home', 'to', 'many', '', 'aryans', '', 'muslims', '', 'gangstas', '', 'latinos', '', 'christians', '', 'italians', '', 'irish', 'and', 'more', '', '', '', 'so', 'scuffles', '', 'death', 'stares', '', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', '', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'wouldn', 't', 'dare', '', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', '', 'forget', 'charm', '', 'forget', 'romance', '', '', 'oz', 'doesn', 't', 'mess', 'around', '', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', '', 'i', 'couldn', 't', 'say', 'i', 'was', 'ready', 'for', 'it', '', 'but', 'as', 'i', 'watched', 'more', '', 'i', 'developed', 'a', 'taste', 'for', 'oz', '', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', '', 'not', 'just', 'violence', '', 'but', 'injustice', '', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', '', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', '', 'well', 'mannered', '', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', '', 'watching', 'oz', '', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', '', '', '', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side', '', 'one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', 'll', 'be', 'hooked', '', 'they', 'are', 'right', '', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', '', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', '', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', '', 'trust', 'me', '', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', '', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', '', 'sex', 'or', 'violence', '', 'its', 'is', 'hardcore', '', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', '', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', '', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', '', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', '', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', '', 'em', 'city', 'is', 'home', 'to', 'many', '', 'aryans', '', 'muslims', '', 'gangstas', '', 'latinos', '', 'christians', '', 'italians', '', 'irish', 'and', 'more', '', '', '', 'so', 'scuffles', '', 'death', 'stares', '', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', '', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'wouldn', 't', 'dare', '', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', '', 'forget', 'charm', '', 'forget', 'romance', '', '', 'oz', 'doesn', 't', 'mess', 'around', '', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', '', 'i', 'couldn', 't', 'say', 'i', 'was', 'ready', 'for', 'it', '', 'but', 'as', 'i', 'watched', 'more', '', 'i', 'developed', 'a', 'taste', 'for', 'oz', '', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', '', 'not', 'just', 'violence', '', 'but', 'injustice', '', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', '', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', '', 'well', 'mannered', '', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', '', 'watching', 'oz', '', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', '', '', '', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side', '']\n"
     ]
    }
   ],
   "source": [
    "# 다시 sentence에 temp_data 결과 병합\n",
    "\n",
    "for a in range(len(temp_data)):\n",
    "    for b in range(len(temp_data[a])):\n",
    "        sentence[a].append(temp_data[a][b])\n",
    "    \n",
    "print(sentence[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "# 학습 데이터에 40000 할당 (총 50000)\n",
    "reviews_train_clean = sentence[:40000]\n",
    "train_y = label[:40000]\n",
    "\n",
    "# 나머지 10000은 검증 데이터 할당\n",
    "reviews_test_clean = sentence[40000:]\n",
    "test_y = label[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer : 문서 집합에서 단어 토큰을 생성, 각 단어의 수를 세어 bag of words로 인코딩한 벡터 생성(단어 빈도 수 측정용도?)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True) # 성능 개선을 위한 binary 이진분류 옵션\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01 , Accuracy : 0.8809\n",
      "C =  0.05 , Accuracy : 0.8872\n",
      "C =  0.25 , Accuracy : 0.8861\n",
      "C =  0.5 , Accuracy : 0.8845\n",
      "C =  1 , Accuracy : 0.8823\n"
     ]
    }
   ],
   "source": [
    "# LogistiRegression 회귀분석을 이용한 최적의 파라미터 찾기\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, train_y, test_size = 0.25, random_state = 17)\n",
    "\n",
    "for c in[0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C = c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(\"C = \", c,\", Accuracy :\", accuracy_score(y_val, lr.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy :  0.8884\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.05)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Final Accuracy : \", accuracy_score(test_y, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_new = ['This movie was excellent', 'absolute joy ride',\n",
    "              'Steven Seagal was terrible', 'Steven Seagal shined through.',\n",
    "              'this was certainly a movie', 'Two thumbs up', 'I fell asleep halfway through',\n",
    "              \"We can't wait for the sequel!!\", 'I can recommend this highly enough',\n",
    "              'instant classic.', 'Steven Seagal was amazing. His perfomance was Oscar-worthy.',\n",
    "              'I love it']\n",
    "\n",
    "reviews_new_counts = cv.transform(reviews_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie was excellent  ->  positive\n",
      "absolute joy ride  ->  positive\n",
      "Steven Seagal was terrible  ->  negative\n",
      "Steven Seagal shined through.  ->  negative\n",
      "this was certainly a movie  ->  negative\n",
      "Two thumbs up  ->  positive\n",
      "I fell asleep halfway through  ->  negative\n",
      "We can't wait for the sequel!!  ->  negative\n",
      "I can recommend this highly enough  ->  positive\n",
      "instant classic.  ->  positive\n",
      "Steven Seagal was amazing. His perfomance was Oscar-worthy.  ->  positive\n",
      "I love it  ->  positive\n"
     ]
    }
   ],
   "source": [
    "pred = final_model.predict(reviews_new_counts)\n",
    "\n",
    "for review, category in zip(reviews_new,pred):\n",
    "    print(review,\" -> \", category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
