{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 검사 생략\n"
     ]
    }
   ],
   "source": [
    "# Text classification Example\n",
    "\n",
    "# Data Load\n",
    "\n",
    "import csv\n",
    "\n",
    "file = open (\"./IMDB_Dataset.csv\", \"r\", encoding='UTF-8')  # ./ 기본경로는 Script가 저장되는 장소\n",
    "rdr = csv.reader(file)\n",
    "\n",
    "sentence = []\n",
    "label = []\n",
    "\n",
    "for index, line in enumerate(rdr):\n",
    "    if index == 0:\n",
    "        continue\n",
    "    sentence.append(line[0].strip()) # sentence 리스트에 리뷰 내용 추가, strip() 함수는 문자열 양쪽의 공백 제거 (x)\n",
    "    label.append(line[1].strip())    # label 리스트에 긍정, 부정 추가 (y)\n",
    "    \n",
    "# print data, not preprocessing (원본)\n",
    "print(\"원본 검사 생략\")\n",
    "#print(sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming 라이브러리 선언 및 테스트\n",
    "\n",
    "from __future__ import print_function\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "#print(stemmer.stem(\"hook\")) # stemmer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re 라이브러리로 특수문자 제거\n",
    "import re\n",
    "\n",
    "# 저장용 임시 리스트\n",
    "#temp_data = [len(sentence)]\n",
    "t_data=[]\n",
    "# 소문자로 변환 .lower(), 불필요한 특수문자 제거\n",
    "for i in range(len(sentence)):\n",
    "    sentence[i] = sentence[i].lower() # lower() : 모든 문자를 소문자로 변환\n",
    "    sentence[i] = re.sub(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\", ' ', sentence[i])\n",
    "    sentence[i] = re.sub(\"[.;:!\\'?,\\\"()|[\\]]\", ' ', sentence[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', 'you', 'll', 'be', 'hooked', 'they', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', 'trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence', 'its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'em', 'city', 'is', 'home', 'to', 'many', 'aryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'and', 'more', 'so', 'scuffles', 'death', 'stares', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'wouldn', 't', 'dare', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romance', 'oz', 'doesn', 't', 'mess', 'around', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'i', 'couldn', 't', 'say', 'i', 'was', 'ready', 'for', 'it', 'but', 'as', 'i', 'watched', 'more', 'i', 'developed', 'a', 'taste', 'for', 'oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'not', 'just', 'violence', 'but', 'injustice', 'crooked', 'guards', 'who', 'll', 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', 'who', 'll', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'mannered', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'watching', 'oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side']\n"
     ]
    }
   ],
   "source": [
    "# 단어 단위로 분할\n",
    "result=[]\n",
    "for i in sentence:\n",
    "    result.append(i.split()) # 워드 단위로 분할 후 리스트에 저장\n",
    "    \n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the other review has mention that after watch just 1 oz episod you ll be hook they are right as this is exact what happen with me the first thing that struck me about oz was it brutal and unflinch scene of violenc which set in right from the word go trust me this is not a show for the faint heart or timid this show pull no punch with regard to drug sex or violenc it is hardcor in the classic use of the word it is call oz as that is the nicknam given to the oswald maximum secur state penitentari it focus main on emerald citi an experiment section of the prison where all the cell have glass front and face inward so privaci is not high on the agenda em citi is home to mani aryan muslim gangsta latino christian italian irish and more so scuffl death stare dodgi deal and shadi agreement are never far away i would say the main appeal of the show is due to the fact that it goe where other show wouldn t dare forget pretti pictur paint for mainstream audienc forget charm forget romanc oz doesn t mess around the first episod i ever saw struck me as so nasti it was surreal i couldn t say i was readi for it but as i watch more i develop a tast for oz and got accustom to the high level of graphic violenc not just violenc but injustic crook guard who ll be sold out for a nickel inmat who ll kill on order and get away with it well manner middl class inmat be turn into prison bitch due to their lack of street skill or prison experi watch oz you may becom comfort with what is uncomfort view that if you can get in touch with your darker side\n"
     ]
    }
   ],
   "source": [
    "sentence=[] # 결과를 받기위해 초기화\n",
    "for i in range(len(result)):\n",
    "    tmp=[]\n",
    "    string=\"\"\n",
    "    for j in result[i]:\n",
    "        tmp.append(stemmer.stem(j)) # stemming\n",
    "    \n",
    "    for k in tmp:\n",
    "        string= string+k+' ' # 문자열로 추합\n",
    "        \n",
    "    sentence.append(string.rstrip()) # 좌우 불필요 공백 제거후 추합\n",
    "print(sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "# 학습 데이터에 40000 할당 (총 50000)\n",
    "reviews_train_clean = sentence[:40000]\n",
    "train_y = label[:40000]\n",
    "\n",
    "# 나머지 10000은 검증 데이터 할당\n",
    "reviews_test_clean = sentence[40000:]\n",
    "test_y = label[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer : 문서 집합에서 단어 토큰을 생성, 각 단어의 수를 세어 bag of words로 인코딩한 벡터 생성(단어 빈도 수 측정용도?)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True) # 성능 개선을 위한 binary 이진분류 옵션\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\venv\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01 , Accuracy : 0.8754\n",
      "C =  0.05 , Accuracy : 0.8817\n",
      "C =  0.25 , Accuracy : 0.8794\n",
      "C =  0.5 , Accuracy : 0.875\n",
      "C =  1 , Accuracy : 0.8736\n"
     ]
    }
   ],
   "source": [
    "# LogistiRegression 회귀분석을 이용한 최적의 파라미터 찾기\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, train_y, test_size = 0.25, random_state = 17)\n",
    "\n",
    "for c in[0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C = c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(\"C = \", c,\", Accuracy :\", accuracy_score(y_val, lr.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy :  0.8795\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.05)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Final Accuracy : \", accuracy_score(test_y, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_new = ['This movie was excellent', 'absolute joy ride',\n",
    "              'Steven Seagal was terrible', 'Steven Seagal shined through.',\n",
    "              'this was certainly a movie', 'Two thumbs up', 'I fell asleep halfway through',\n",
    "              \"We can't wait for the sequel!!\", 'I can recommend this highly enough',\n",
    "              'instant classic.', 'Steven Seagal was amazing. His perfomance was Oscar-worthy.',\n",
    "              'I love it']\n",
    "\n",
    "reviews_new_counts = cv.transform(reviews_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie was excellent  ->  negative\n",
      "absolute joy ride  ->  positive\n",
      "Steven Seagal was terrible  ->  negative\n",
      "Steven Seagal shined through.  ->  negative\n",
      "this was certainly a movie  ->  negative\n",
      "Two thumbs up  ->  positive\n",
      "I fell asleep halfway through  ->  negative\n",
      "We can't wait for the sequel!!  ->  positive\n",
      "I can recommend this highly enough  ->  positive\n",
      "instant classic.  ->  positive\n",
      "Steven Seagal was amazing. His perfomance was Oscar-worthy.  ->  negative\n",
      "I love it  ->  positive\n"
     ]
    }
   ],
   "source": [
    "pred = final_model.predict(reviews_new_counts)\n",
    "\n",
    "for review, category in zip(reviews_new,pred):\n",
    "    print(review,\" -> \", category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
