{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "NB_Grid search_stemming.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyeon-Kang/NLP/blob/master/week03_Naive_Bayes_model/NB_Grid%20search_stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TK3mz_vwXbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 20개의 뉴스 카테고리 분류\n",
        "# Naive Bayes 알고리즘을 통한 다항 분류\n",
        "# Grid Search 를 사용하여 입력 범위내 최적의 파라미터 도출 \n",
        "\n",
        "# Stemmer 전처리를 사용한 경우 Naive Bayes의 성능이 변하는지 실험\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "twenty_train = fetch_20newsgroups(subset = 'train', shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j14iD8VJwXbK",
        "colab_type": "code",
        "colab": {},
        "outputId": "88c8f967-e49a-4032-d3b6-c68b3c7464a4"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer() # bag of word 형식으로 단어마다 인덱스를 부여한 벡터 생성\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "print('Count Vector : ', X_train_counts.shape) # (문서의 개수, 단어의 개수)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count Vector :  (11314, 130107)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmdLF41bwXbN",
        "colab_type": "code",
        "colab": {},
        "outputId": "fd805f79-93a3-4ac3-ec5e-704305020112"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "# TF, IDF\n",
        "tfidf_transformer = TfidfTransformer() # 단어 빈도와 문서 빈도를 통해 특정 문서 및 문서 집단에서의 단어 가중치 산출\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "print('Tfidf : ', X_train_tfidf.shape) # (문서의 개수, 단어의 개수)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tfidf :  (11314, 130107)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_XoElsjwXbP",
        "colab_type": "code",
        "colab": {},
        "outputId": "ebdc0b20-b94c-4067-f38d-4a7ba8253558"
      },
      "source": [
        "# 다항분류\n",
        "print(' ---- Naive Bayes algorithm ---- ')\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB # 다항 분류 알고리즘\n",
        "\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 파이프라인을 통해 전처리 단계와 학습 모델을 결합한 구조체 작성\n",
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                    ('tfidf', TfidfTransformer()),\n",
        "                    ('clf', MultinomialNB())])\n",
        "\n",
        "# 작성한 구조체에 데이터를 넣어 학습 진행\n",
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "twenty_test = fetch_20newsgroups(subset = 'test', shuffle = True) \n",
        "predicted = text_clf.predict(twenty_test.data) # 구축한 학습 모델 테스트\n",
        "print('Accuracy : ', np.mean(predicted == twenty_test.target))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ---- Naive Bayes algorithm ---- \n",
            "Accuracy :  0.7738980350504514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEFLOpOdwXbR",
        "colab_type": "code",
        "colab": {},
        "outputId": "565ee7f6-cdb5-4f83-aad6-dc10ddae0669"
      },
      "source": [
        "# Grid search를 통한 최적의 파라미터 경우 찾기\n",
        "print(' ---- Grid serach : Naive Bayes algorithm ---- ')\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'vect__ngram_range' : [(1,1), (1,2)], # 단어별로 학습, bigram 단위로 학습\n",
        "             'tfidf__use_idf' : (True, False), # TF-IDF 가중치 사용 여부\n",
        "             'clf__alpha' : (1e-2, 1e-3)} # 나이브 베이즈 다항분류의 페널티 정도 (0.01 or 0.001)\n",
        "\n",
        "gs_clf = GridSearchCV(text_clf, parameters, n_jobs = -1) # -1 : 모든 cpu 사용\n",
        "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)\n",
        "\n",
        "print(gs_clf.best_score_)\n",
        "print(gs_clf.best_params_) # 도출한 최적 파라미터\n",
        "\n",
        "# print('Accuracy : ', np.mean(predicted == twenty_test.target))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ---- Grid serach : Naive Bayes algorithm ---- \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "c:\\python\\venv\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9067526957751458\n",
            "{'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgnQxLzWwXbT",
        "colab_type": "code",
        "colab": {},
        "outputId": "4a57f3a3-592d-4cfe-9e1d-cc04dff31d6f"
      },
      "source": [
        "# stemmer를 사용하여 단어의 원형으로 바꾼 뒤  Naive bayes 알고리즘을 통해 분류한다면\n",
        "# 더 좋은 효율이 나올까?\n",
        "print('---- Naive bayes with Stemming ----')\n",
        "\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "class StemmedCountVectorizer(CountVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super(StemmedCountVectorizer, self).build_analyzer() # stemming을 한 뒤 CountVectorize 적용\n",
        "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
        "\n",
        "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
        "\n",
        "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), # stemming된 데이터를 CountVetorizer 적용\n",
        "                            ('tfidf', TfidfTransformer()),\n",
        "                            ('mnb', MultinomialNB(fit_prior=False))])\n",
        "\n",
        "text_mnb_stemmed = text_mnb_stemmed.fit(twenty_train.data, twenty_train.target)\n",
        "predicted_mnb_stemmed = text_mnb_stemmed.predict(twenty_test.data)\n",
        "print('Accuracy : ', np.mean(predicted_mnb_stemmed == twenty_test.target))\n",
        "\n",
        "# 더 좋은 데이터가 나옴을 확인"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---- Naive bayes with Stemming ----\n",
            "Accuracy :  0.8167817312798725\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}